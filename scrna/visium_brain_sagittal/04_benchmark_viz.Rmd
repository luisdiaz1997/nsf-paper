---
title: "Benchmarking Visualization"
author: "Will Townes"
output: html_document
---

```{r}
library(tidyverse)
theme_set(theme_bw())
fp<-file.path
pth<-"scrna/visium_brain_sagittal"
plt_pth<-fp(pth,"results/plots")
if(!dir.exists(plt_pth)){
    dir.create(plt_pth,recursive=TRUE)
}
```

```{r}
d0<-read.csv(fp(pth,"results/benchmark.csv"))
d0$converged<-as.logical(d0$converged)
#d0$model<-plyr::mapvalues(d0$model,c("FA","RSF","PNMF","NSFH","NSF"),c("FA","RSF","PNMF","NSFH","NSF"))
d<-subset(d0,converged==TRUE)
d$model<-paste0(d$model," (",d$lik,")")
unique(d$model)
keep<-c("FA (gau)","MEFISTO (gau)","RSF (gau)","PNMF (nb)","PNMF (poi)","NSFH (nb)","NSFH (poi)","NSF (nb)","NSF (poi)")

d<-subset(d,model %in% keep)
d$model<-factor(d$model,levels=keep)
d$dim<-factor(d$L,levels=sort(unique(d$L)))
d$M[is.na(d$M)]<-2363
d$IPs<-factor(d$M,levels=sort(unique(d$M)))
d$standard_kernel<-TRUE
d$standard_kernel[(d$model %in% c("RSF (gau)","NSFH (nb)","NSFH (poi)","NSF (nb)","NSF (poi)")) & d$kernel=="ExponentiatedQuadratic"]<-FALSE
d1<-subset(d,V==5 & standard_kernel)
```
subset of models for simplified main figure
```{r}
d2<-subset(d1,M==2363 | (model %in% c("PNMF (poi)","FA (gau)")))
d2a<-subset(d2,(model %in% c("PNMF (poi)","NSFH (poi)","NSF (poi)")) & sz=="scanpy")
d2b<-subset(d2,model %in% c("FA (gau)","RSF (gau)","MEFISTO (gau)"))
d2<-rbind(d2a,d2b)
#d2$model<-factor(d2$model,levels=)
d2$model<-plyr::mapvalues(d2$model,c("FA (gau)","MEFISTO (gau)","RSF (gau)","PNMF (poi)","NSFH (poi)","NSF (poi)"),c("FA","MEFISTO","RSF","PNMF","NSFH","NSF"))
ggplot(d2,aes(x=model,y=dev_val_mean,color=dim,shape=lik))+geom_point(size=6,position=position_dodge(width=0.5))+ylab("validation deviance (mean)")+ylim(range(d2$dev_val_mean)*c(.95,1.02))
ggsave(fp(plt_pth,"vz_brn_gof_dev_val_mean_main.pdf"),width=5,height=2.5)

#linear regressions for statistical significance
d2$realvalued<-d2$model %in% c("FA","MEFISTO","RSF")
#d2$dim_numeric<-as.numeric(as.character(d2$dim))
summary(lm(dev_val_mean~realvalued+dim,data=d2))
summary(lm(dev_val_mean~model,data=d2))
t.test(dev_val_mean~model,data=subset(d2,model %in% c("NSF","RSF")), var.equal=TRUE, alternative="less")
d2$unsupervised<-d2$model %in% c("FA","PNMF")
d2$unsupervised[d2$model=="MEFISTO"]<-NA
summary(lm(dev_val_mean~realvalued+dim+unsupervised,data=d2))
t.test(dev_val_mean~model,data=subset(d2,model %in% c("RSF","MEFISTO")), var.equal=TRUE,alternative="greater")

d2_no60<-subset(d2,dim!="60")
d2_no60$dim<-factor(d2_no60$dim)
ggplot(d2_no60,aes(x=model,y=rmse_val,color=dim,shape=lik))+geom_point(size=6,position=position_dodge(width=0.5))+ylab("validation RMSE")+ylim(range(d2$rmse_val)*c(.95,1.02))
ggsave(fp(plt_pth,"vz_brn_gof_rmse_val_simple.pdf"),width=5,height=2.5)

ggplot(d2_no60,aes(x=model,y=sparsity,color=dim,shape=lik))+geom_point(size=6,position=position_dodge(width=0.5))+ylab("loadings zero fraction")+ylim(range(d2$sparsity)*c(.95,1.02))
ggsave(fp(plt_pth,"vz_brn_sparsity_simple.pdf"),width=5,height=2.5)
```

NSF vs NSFH

```{r}
d3<-subset(d,grepl("NSF",model)&kernel=="MaternThreeHalves" & sz=="scanpy" & V==5 & dim!="60")
ggplot(d3,aes(x=model,y=dev_tr_mean,color=dim,shape=IPs))+geom_point(size=4,position=position_dodge(width=0.6))+ylab("training deviance (mean)")
ggsave(fp(plt_pth,"vz_brn_gof_dev_tr_nsf_vs_nsfh.pdf"),width=6,height=3)
```

```{r}
#training deviance - average
ggplot(d1,aes(x=model,y=dev_tr_mean,color=dim,shape=IPs))+geom_jitter(size=5,width=.2,height=0)+ylab("training deviance (mean)")+theme(legend.position = "top")
ggsave(fp(plt_pth,"vz_brn_gof_dev_tr_mean.pdf"),width=8,height=3)

#training deviance - max
ggplot(d1,aes(x=model,y=dev_tr_max,color=dim,shape=IPs))+geom_jitter(size=5,width=.2,height=0)+ylab("training deviance (max)")#+scale_y_log10()

#validation deviance - mean
ggplot(d1,aes(x=model,y=dev_val_mean,color=dim,shape=IPs))+geom_jitter(size=4,width=.4,height=0)+ylab("validation deviance (mean)")+theme(legend.position="none")
ggsave(fp(plt_pth,"vz_brn_gof_dev_val_mean.pdf"),width=8,height=2.5)

#validation deviance - max
ggplot(d1,aes(x=model,y=dev_val_max,color=dim,shape=IPs))+geom_jitter(size=3,width=.2,height=0)+ylab("validation deviance (max)")#+scale_y_log10()

#sparsity
ggplot(d1,aes(x=model,y=sparsity,color=dim,shape=IPs))+geom_jitter(size=4,width=.3,height=0)+ylab("sparsity of loadings")+theme(legend.position="none")
ggsave(fp(plt_pth,"vz_brn_sparsity.pdf"),width=6,height=2.5)

#wall time
ggplot(d1,aes(x=model,y=wtime/60,color=IPs,shape=dim))+geom_jitter(size=5,width=.2,height=0)+ylab("wall time (min)")+scale_y_log10()+theme(legend.position="top")
ggsave(fp(plt_pth,"vz_brn_wtime.pdf"),width=6,height=3)
ggplot(d1,aes(x=dim,y=wtime/60,color=IPs))+geom_jitter(size=3,width=.2,height=0)+ylab("wall time (min)")+scale_y_log10()

#processor time
ggplot(d1,aes(x=model,y=ptime/60,color=IPs,shape=dim))+geom_jitter(size=5,width=.2,height=0)+ylab("processor time")+scale_y_log10()+theme(legend.position="none")
ggsave(fp(plt_pth,"vz_brn_ptime.pdf"),width=6,height=2.5)
```

Effect of using size factors

```{r}
d2<-subset(d1,model %in% c("NSF (nb)","NSF (poi)","NSFH (nb)","NSFH (poi)","PNMF (nb)","PNMF (poi)"))
d2$model<-factor(d2$model)
d2$dim<-factor(d2$L,levels=sort(unique(d2$L)))
d2$M[is.na(d2$M)]<-2363
d2$IPs<-factor(d2$M,levels=sort(unique(d2$M)))
```

```{r}
ggplot(d2,aes(x=sz,y=dev_tr_mean,color=dim,shape=IPs))+geom_jitter(size=5,width=.2,height=0)+ylab("training deviance (mean)")+theme(legend.position = "top")+facet_wrap(~model,ncol=2,scales="free")

ggplot(d2,aes(x=sz,y=dev_val_mean,color=dim,shape=IPs))+geom_jitter(size=5,width=.2,height=0)+ylab("validation deviance (mean)")+theme(legend.position = "top")+facet_wrap(~model,ncol=2,scales="free")
```

Reviewer comment: GOF metrics with validation 20% of data instead of 5%
```{r}
d2<-subset(d,V==20 & standard_kernel)
d2<-subset(d2,M==2363 | (model %in% c("PNMF (poi)","FA (gau)")))
d2a<-subset(d2,(model %in% c("PNMF (poi)","NSFH (poi)","NSF (poi)")) & sz=="scanpy")
d2b<-subset(d2,model %in% c("FA (gau)","RSF (gau)","MEFISTO (gau)"))
d2<-rbind(d2a,d2b)
#d2$model<-factor(d2$model,levels=)
d2$model<-plyr::mapvalues(d2$model,c("FA (gau)","MEFISTO (gau)","RSF (gau)","PNMF (poi)","NSFH (poi)","NSF (poi)"),c("FA","MEFISTO","RSF","PNMF","NSFH","NSF"))
ggplot(d2,aes(x=model,y=dev_val_mean,color=dim,shape=lik))+geom_point(size=6,position=position_dodge(width=0.5))+ylab("validation deviance (mean)")+ylim(range(d2$dev_val_mean)*c(.95,1.02))
ggsave(fp(plt_pth,"vz_brn_gof_dev_val_mean_main_V20.pdf"),width=5,height=2.5)

ggplot(d2,aes(x=model,y=rmse_val,color=dim,shape=lik))+geom_point(size=6,position=position_dodge(width=0.5))+ylab("validation RMSE")+ylim(range(d2$rmse_val)*c(.95,1.02))
ggsave(fp(plt_pth,"vz_brn_gof_rmse_val_simple_V20.pdf"),width=5,height=2.5)
```

Reviewer comment: Matern vs RBF kernels
```{r}
d2<-subset(d,V==5 & M==1000)
d2a<-subset(d2,(model %in% c("NSFH (poi)","NSF (poi)")) & sz=="scanpy")
d2b<-subset(d2,model %in% c("RSF (gau)","MEFISTO (gau)"))
d2<-rbind(d2a,d2b)
#d2$model<-factor(d2$model,levels=)
d2$model<-plyr::mapvalues(d2$model,c("MEFISTO (gau)","RSF (gau)","NSFH (poi)","NSF (poi)"),c("MEFISTO","RSF","NSFH","NSF"))
ggplot(d2,aes(x=model,y=dev_val_mean,color=dim,shape=kernel))+geom_point(size=6,position=position_dodge(width=0.7))+ylab("validation deviance (mean)")+ylim(range(d2$dev_val_mean)*c(.95,1.02))
ggsave(fp(plt_pth,"vz_brn_gof_dev_val_kernels.pdf"),width=5,height=2.5)

ggplot(d2,aes(x=model,y=rmse_val,color=dim,shape=kernel))+geom_point(size=6,position=position_dodge(width=0.7))+ylab("validation RMSE")+ylim(range(d2$rmse_val)*c(.95,1.02))
ggsave(fp(plt_pth,"vz_brn_gof_rmse_val_kernels.pdf"),width=5,height=2.5)
```

numerical stability of different kernel choices
```{r}
d0<-read.csv(fp(pth,"results/benchmark.csv"))
d0$converged<-as.logical(d0$converged)
table(d0$converged)
d1<-subset(d0,V==5)# & M==2363)
d1a<-subset(d1,model=="RSF" & lik=="gau")
d1b<-subset(d1,model %in% c("NSF","NSFH") & lik=="poi")
d<-rbind(d1a,d1b)
d2 <- d %>% group_by(kernel,M,model,lik) %>% summarize(total_runs=length(converged),converged=sum(converged))
```
